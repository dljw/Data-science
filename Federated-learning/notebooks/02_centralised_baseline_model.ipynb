{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>...</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Size</th>\n",
       "      <th>Super_Bowl</th>\n",
       "      <th>Labor_Day</th>\n",
       "      <th>Thanksgiving</th>\n",
       "      <th>Christmas</th>\n",
       "      <th>week</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>24924.50</td>\n",
       "      <td>False</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>50605.27</td>\n",
       "      <td>False</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>13740.12</td>\n",
       "      <td>False</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>39954.04</td>\n",
       "      <td>False</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>32229.38</td>\n",
       "      <td>False</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  Dept        Date  Weekly_Sales  IsHoliday  Temperature  Fuel_Price  \\\n",
       "0      1     1  2010-02-05      24924.50      False        42.31       2.572   \n",
       "1      1     2  2010-02-05      50605.27      False        42.31       2.572   \n",
       "2      1     3  2010-02-05      13740.12      False        42.31       2.572   \n",
       "3      1     4  2010-02-05      39954.04      False        42.31       2.572   \n",
       "4      1     5  2010-02-05      32229.38      False        42.31       2.572   \n",
       "\n",
       "   MarkDown1  MarkDown2  MarkDown3  ...  Unemployment  Type    Size  \\\n",
       "0        0.0        0.0        0.0  ...         8.106     A  151315   \n",
       "1        0.0        0.0        0.0  ...         8.106     A  151315   \n",
       "2        0.0        0.0        0.0  ...         8.106     A  151315   \n",
       "3        0.0        0.0        0.0  ...         8.106     A  151315   \n",
       "4        0.0        0.0        0.0  ...         8.106     A  151315   \n",
       "\n",
       "   Super_Bowl Labor_Day  Thanksgiving  Christmas  week  month  year  \n",
       "0       False     False         False      False     5      2  2010  \n",
       "1       False     False         False      False     5      2  2010  \n",
       "2       False     False         False      False     5      2  2010  \n",
       "3       False     False         False      False     5      2  2010  \n",
       "4       False     False         False      False     5      2  2010  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/raw/clean_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1q/26x3nv656dg2gv4xzbytws5m0000gn/T/ipykernel_35779/113154508.py:7: FutureWarning: Value based partial slicing on non-monotonic DatetimeIndexes with non-existing keys is deprecated and will raise a KeyError in a future Version.\n",
      "  test = df.loc['2012-10-01':].reset_index()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((408369, 23), (11843, 23))"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Date'] = pd.to_datetime(df[\"Date\"])\n",
    "df.index = df['Date']\n",
    "# df = df.resample(\"W\").mean()\n",
    "df = df.drop(['Date'], axis=1)\n",
    "# df['Weekly_Sales'] = np.log(df['Weekly_Sales'])\n",
    "train = df.loc[:'2012-10-01'].reset_index()\n",
    "test = df.loc['2012-10-01':].reset_index()\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.set_index(\"Date\")\n",
    "train['Weekly_sales_lag'] = train['Weekly_Sales'].shift(4)\n",
    "train = train.reset_index()\n",
    "train = train.dropna()\n",
    "\n",
    "test = test.set_index(\"Date\")\n",
    "test['Weekly_sales_lag'] = test['Weekly_Sales'].shift(4)\n",
    "test = test.reset_index()\n",
    "test = test.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['Weekly_Sales'], axis=1)\n",
    "y_train = np.log(train['Weekly_Sales'])\n",
    "\n",
    "X_test = test.drop(['Weekly_Sales'], axis=1)\n",
    "y_test = np.log(test['Weekly_Sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train['Date'] = pd.to_datetime(X_train['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Store', 'Dept', 'IsHoliday', 'Temperature', 'Fuel_Price',\n",
       "       'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI',\n",
       "       'Unemployment', 'Type', 'Size', 'Super_Bowl', 'Labor_Day',\n",
       "       'Thanksgiving', 'Christmas', 'week', 'month', 'year',\n",
       "       'Weekly_sales_lag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_FEATURE_KEYS = [\n",
    "    'Dept',\n",
    "    'IsHoliday',\n",
    "    \"Super_Bowl\",\n",
    "    \"Type\",\n",
    "    \"Size\",\n",
    "    \"Labor_Day\",\n",
    "    \"Thanksgiving\",\n",
    "    \"Christmas\",\n",
    "    \"year\",\n",
    "    \"week\"\n",
    "]\n",
    "\n",
    "NUMERIC_FEATURE_KEYS = [\n",
    "    \"Temperature\",\n",
    "    \"Fuel_Price\",\n",
    "    \"MarkDown1\",\n",
    "    \"MarkDown2\",\n",
    "    \"MarkDown3\",\n",
    "    \"MarkDown4\",\n",
    "    \"MarkDown5\",\n",
    "    \"CPI\",\n",
    "    \"Weekly_sales_lag\"\n",
    "]\n",
    "\n",
    "# ORDINAL_FEATURE_KEYS = [\n",
    "#     \"year\",\n",
    "#     \"week\"\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(\n",
    "    [(\"Numeric\", StandardScaler(), NUMERIC_FEATURE_KEYS),\n",
    "     (\"Categorical\", OneHotEncoder(), CATEGORICAL_FEATURE_KEYS)\n",
    "    ])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[('preprocessor', ct)])\n",
    "X_train_trans = ct.fit_transform(X_train)\n",
    "X_test_trans = ct.transform(X_test)\n",
    "trans_col = pipeline.named_steps['preprocessor'].transformers_[1][1].get_feature_names_out(CATEGORICAL_FEATURE_KEYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trans = pd.DataFrame(X_train_trans.toarray(), columns=NUMERIC_FEATURE_KEYS + trans_col.tolist())\n",
    "X_test_trans = pd.DataFrame(X_test_trans.toarray(),columns=NUMERIC_FEATURE_KEYS + trans_col.tolist())\n",
    "# X_train_trans['week'] = X_train['week']\n",
    "# X_test_trans['week'] = X_test['week']\n",
    "# X_train_trans = X_train_trans.dropna()\n",
    "# X_test_trans = X_test_trans.dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>MarkDown4</th>\n",
       "      <th>MarkDown5</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Weekly_sales_lag</th>\n",
       "      <th>Dept_1</th>\n",
       "      <th>...</th>\n",
       "      <th>week_43</th>\n",
       "      <th>week_44</th>\n",
       "      <th>week_45</th>\n",
       "      <th>week_46</th>\n",
       "      <th>week_47</th>\n",
       "      <th>week_48</th>\n",
       "      <th>week_49</th>\n",
       "      <th>week_50</th>\n",
       "      <th>week_51</th>\n",
       "      <th>week_52</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.953080</td>\n",
       "      <td>-1.702558</td>\n",
       "      <td>-0.419353</td>\n",
       "      <td>-0.175588</td>\n",
       "      <td>-0.085799</td>\n",
       "      <td>-0.274567</td>\n",
       "      <td>-0.380216</td>\n",
       "      <td>1.023768</td>\n",
       "      <td>0.390149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.953080</td>\n",
       "      <td>-1.702558</td>\n",
       "      <td>-0.419353</td>\n",
       "      <td>-0.175588</td>\n",
       "      <td>-0.085799</td>\n",
       "      <td>-0.274567</td>\n",
       "      <td>-0.380216</td>\n",
       "      <td>1.023768</td>\n",
       "      <td>1.518722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.953080</td>\n",
       "      <td>-1.702558</td>\n",
       "      <td>-0.419353</td>\n",
       "      <td>-0.175588</td>\n",
       "      <td>-0.085799</td>\n",
       "      <td>-0.274567</td>\n",
       "      <td>-0.380216</td>\n",
       "      <td>1.023768</td>\n",
       "      <td>-0.101363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.953080</td>\n",
       "      <td>-1.702558</td>\n",
       "      <td>-0.419353</td>\n",
       "      <td>-0.175588</td>\n",
       "      <td>-0.085799</td>\n",
       "      <td>-0.274567</td>\n",
       "      <td>-0.380216</td>\n",
       "      <td>1.023768</td>\n",
       "      <td>1.050641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.953080</td>\n",
       "      <td>-1.702558</td>\n",
       "      <td>-0.419353</td>\n",
       "      <td>-0.175588</td>\n",
       "      <td>-0.085799</td>\n",
       "      <td>-0.274567</td>\n",
       "      <td>-0.380216</td>\n",
       "      <td>1.023768</td>\n",
       "      <td>0.711171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408360</th>\n",
       "      <td>0.258408</td>\n",
       "      <td>1.429542</td>\n",
       "      <td>0.325591</td>\n",
       "      <td>-0.171579</td>\n",
       "      <td>-0.085531</td>\n",
       "      <td>0.131404</td>\n",
       "      <td>0.398139</td>\n",
       "      <td>0.535703</td>\n",
       "      <td>-0.318996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408361</th>\n",
       "      <td>0.258408</td>\n",
       "      <td>1.429542</td>\n",
       "      <td>0.325591</td>\n",
       "      <td>-0.171579</td>\n",
       "      <td>-0.085531</td>\n",
       "      <td>0.131404</td>\n",
       "      <td>0.398139</td>\n",
       "      <td>0.535703</td>\n",
       "      <td>0.286505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408362</th>\n",
       "      <td>0.258408</td>\n",
       "      <td>1.429542</td>\n",
       "      <td>0.325591</td>\n",
       "      <td>-0.171579</td>\n",
       "      <td>-0.085531</td>\n",
       "      <td>0.131404</td>\n",
       "      <td>0.398139</td>\n",
       "      <td>0.535703</td>\n",
       "      <td>-0.045078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408363</th>\n",
       "      <td>0.258408</td>\n",
       "      <td>1.429542</td>\n",
       "      <td>0.325591</td>\n",
       "      <td>-0.171579</td>\n",
       "      <td>-0.085531</td>\n",
       "      <td>0.131404</td>\n",
       "      <td>0.398139</td>\n",
       "      <td>0.535703</td>\n",
       "      <td>1.376635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408364</th>\n",
       "      <td>0.258408</td>\n",
       "      <td>1.429542</td>\n",
       "      <td>0.325591</td>\n",
       "      <td>-0.171579</td>\n",
       "      <td>-0.085531</td>\n",
       "      <td>0.131404</td>\n",
       "      <td>0.398139</td>\n",
       "      <td>0.535703</td>\n",
       "      <td>-0.583765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>408365 rows × 198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Temperature  Fuel_Price  MarkDown1  MarkDown2  MarkDown3  MarkDown4  \\\n",
       "0         -0.953080   -1.702558  -0.419353  -0.175588  -0.085799  -0.274567   \n",
       "1         -0.953080   -1.702558  -0.419353  -0.175588  -0.085799  -0.274567   \n",
       "2         -0.953080   -1.702558  -0.419353  -0.175588  -0.085799  -0.274567   \n",
       "3         -0.953080   -1.702558  -0.419353  -0.175588  -0.085799  -0.274567   \n",
       "4         -0.953080   -1.702558  -0.419353  -0.175588  -0.085799  -0.274567   \n",
       "...             ...         ...        ...        ...        ...        ...   \n",
       "408360     0.258408    1.429542   0.325591  -0.171579  -0.085531   0.131404   \n",
       "408361     0.258408    1.429542   0.325591  -0.171579  -0.085531   0.131404   \n",
       "408362     0.258408    1.429542   0.325591  -0.171579  -0.085531   0.131404   \n",
       "408363     0.258408    1.429542   0.325591  -0.171579  -0.085531   0.131404   \n",
       "408364     0.258408    1.429542   0.325591  -0.171579  -0.085531   0.131404   \n",
       "\n",
       "        MarkDown5       CPI  Weekly_sales_lag  Dept_1  ...  week_43  week_44  \\\n",
       "0       -0.380216  1.023768          0.390149     0.0  ...      0.0      0.0   \n",
       "1       -0.380216  1.023768          1.518722     0.0  ...      0.0      0.0   \n",
       "2       -0.380216  1.023768         -0.101363     0.0  ...      0.0      0.0   \n",
       "3       -0.380216  1.023768          1.050641     0.0  ...      0.0      0.0   \n",
       "4       -0.380216  1.023768          0.711171     0.0  ...      0.0      0.0   \n",
       "...           ...       ...               ...     ...  ...      ...      ...   \n",
       "408360   0.398139  0.535703         -0.318996     0.0  ...      0.0      0.0   \n",
       "408361   0.398139  0.535703          0.286505     0.0  ...      0.0      0.0   \n",
       "408362   0.398139  0.535703         -0.045078     0.0  ...      0.0      0.0   \n",
       "408363   0.398139  0.535703          1.376635     0.0  ...      0.0      0.0   \n",
       "408364   0.398139  0.535703         -0.583765     0.0  ...      0.0      0.0   \n",
       "\n",
       "        week_45  week_46  week_47  week_48  week_49  week_50  week_51  week_52  \n",
       "0           0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "1           0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "2           0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "3           0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "4           0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "...         ...      ...      ...      ...      ...      ...      ...      ...  \n",
       "408360      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "408361      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "408362      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "408363      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "408364      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "\n",
       "[408365 rows x 198 columns]"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((408365, 198),\n",
       " Index(['Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3',\n",
       "        'MarkDown4', 'MarkDown5', 'CPI', 'Weekly_sales_lag', 'Dept_1',\n",
       "        ...\n",
       "        'week_43', 'week_44', 'week_45', 'week_46', 'week_47', 'week_48',\n",
       "        'week_49', 'week_50', 'week_51', 'week_52'],\n",
       "       dtype='object', length=198))"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_trans.shape, X_train_trans.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Dept_1', 'Dept_2', 'Dept_3', 'Dept_4', 'Dept_5', 'Dept_6',\n",
       "       'Dept_7', 'Dept_8', 'Dept_9', 'Dept_10', 'Dept_11', 'Dept_12',\n",
       "       'Dept_13', 'Dept_14', 'Dept_16', 'Dept_17', 'Dept_18', 'Dept_19',\n",
       "       'Dept_20', 'Dept_21', 'Dept_22', 'Dept_23', 'Dept_24', 'Dept_25',\n",
       "       'Dept_26', 'Dept_27', 'Dept_28', 'Dept_29', 'Dept_30', 'Dept_31',\n",
       "       'Dept_32', 'Dept_33', 'Dept_34', 'Dept_35', 'Dept_36', 'Dept_37',\n",
       "       'Dept_38', 'Dept_39', 'Dept_40', 'Dept_41', 'Dept_42', 'Dept_43',\n",
       "       'Dept_44', 'Dept_45', 'Dept_46', 'Dept_47', 'Dept_48', 'Dept_49',\n",
       "       'Dept_50', 'Dept_51', 'Dept_52', 'Dept_54', 'Dept_55', 'Dept_56',\n",
       "       'Dept_58', 'Dept_59', 'Dept_60', 'Dept_65', 'Dept_67', 'Dept_71',\n",
       "       'Dept_72', 'Dept_74', 'Dept_77', 'Dept_78', 'Dept_79', 'Dept_80',\n",
       "       'Dept_81', 'Dept_82', 'Dept_83', 'Dept_85', 'Dept_87', 'Dept_90',\n",
       "       'Dept_91', 'Dept_92', 'Dept_93', 'Dept_94', 'Dept_95', 'Dept_96',\n",
       "       'Dept_97', 'Dept_98', 'Dept_99', 'IsHoliday_False',\n",
       "       'IsHoliday_True', 'Super_Bowl_False', 'Super_Bowl_True', 'Type_A',\n",
       "       'Type_B', 'Type_C', 'Size_34875', 'Size_37392', 'Size_39690',\n",
       "       'Size_39910', 'Size_41062', 'Size_42988', 'Size_57197',\n",
       "       'Size_70713', 'Size_93188', 'Size_93638', 'Size_103681',\n",
       "       'Size_112238', 'Size_114533', 'Size_118221', 'Size_119557',\n",
       "       'Size_120653', 'Size_123737', 'Size_125833', 'Size_126512',\n",
       "       'Size_128107', 'Size_140167', 'Size_151315', 'Size_152513',\n",
       "       'Size_155078', 'Size_155083', 'Size_158114', 'Size_184109',\n",
       "       'Size_196321', 'Size_200898', 'Size_202307', 'Size_202505',\n",
       "       'Size_203007', 'Size_203742', 'Size_203750', 'Size_203819',\n",
       "       'Size_204184', 'Size_205863', 'Size_206302', 'Size_207499',\n",
       "       'Size_219622', 'Labor_Day_False', 'Labor_Day_True',\n",
       "       'Thanksgiving_False', 'Thanksgiving_True', 'Christmas_False',\n",
       "       'Christmas_True', 'year_2010', 'year_2011', 'year_2012', 'week_1',\n",
       "       'week_2', 'week_3', 'week_4', 'week_5', 'week_6', 'week_7',\n",
       "       'week_8', 'week_9', 'week_10', 'week_11', 'week_12', 'week_13',\n",
       "       'week_14', 'week_15', 'week_16', 'week_17', 'week_18', 'week_19',\n",
       "       'week_20', 'week_21', 'week_22', 'week_23', 'week_24', 'week_25',\n",
       "       'week_26', 'week_27', 'week_28', 'week_29', 'week_30', 'week_31',\n",
       "       'week_32', 'week_33', 'week_34', 'week_35', 'week_36', 'week_37',\n",
       "       'week_38', 'week_39', 'week_40', 'week_41', 'week_42', 'week_43',\n",
       "       'week_44', 'week_45', 'week_46', 'week_47', 'week_48', 'week_49',\n",
       "       'week_50', 'week_51', 'week_52'], dtype=object)"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train_trans, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lr = lr.predict(X_train_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.1545892654894692"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Train\")\n",
    "np.sqrt(mean_squared_error(y_train, pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.16424159368037"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"test\")\n",
    "test_pred_lr = lr.predict(X_test_trans)\n",
    "np.sqrt(mean_squared_error(y_test, test_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-4.605170185988091, 12.169724223396777, 1.9976587043296536)"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.min(), y_test.max(), y_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11839, 198)"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=50)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=50)"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt = RandomForestRegressor(max_depth= 50)\n",
    "rt.fit(X_train_trans, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rt = rt.predict(X_train_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_rt = rt.predict(X_test_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7618383334851071"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_train, pred_rt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-4.605170185988091, 13.448928644517972, 2.050487503404155)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.min(), y_train.max(), y_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7663920528199546"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, test_pred_rt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-4.605170185988091, 12.169724223396777, 1.9976587043296536)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.min(), y_test.max(), y_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel:\n",
    "    def __init__(self, rnn_units=100, return_sequences=False):\n",
    "        # Your code here\n",
    "        self.model = tf.keras.Sequential(\n",
    "            [\n",
    "                # Batch_size, rnn_units. When return_sequence = true, shape = N, input_shape, rnn_units. (useful for stacking RNN)\n",
    "                tf.keras.layers.LSTM(rnn_units, return_sequences=return_sequences),\n",
    "                # tf.keras.layers.SimpleRNN(128),\n",
    "                tf.keras.layers.Dense(10),\n",
    "                tf.keras.layers.Dense(5),\n",
    "                tf.keras.layers.Dense(1),\n",
    "                tf.keras.layers.Dense(1, activation='linear'),\n",
    "            ]\n",
    "        )\n",
    "        self.model.compile(\n",
    "            optimizer=tf.keras.optimizers.RMSprop(),\n",
    "            loss=tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[\n",
    "                tf.keras.metrics.mean_squared_error,\n",
    "                tf.keras.metrics.mean_absolute_error,\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    def fit(self, train_data, epochs, val_data=None, callbacks=None):\n",
    "        # Your code here\n",
    "        history = self.model.fit(\n",
    "            train_data, epochs=epochs, validation_data=val_data, callbacks=callbacks\n",
    "        )\n",
    "        return history\n",
    "\n",
    "    def evaluate(self, eval_data, verbose=0):\n",
    "        # Your code here\n",
    "        result = self.model.evaluate(eval_data, verbose=verbose, return_dict=True)\n",
    "        return result['mean_squared_error'], result['mean_absolute_error']\n",
    "\n",
    "    def predict(self, pred_data):\n",
    "        # Your code here\n",
    "        return self.model.predict(pred_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.Sequential(\n",
    "#             [\n",
    "#                 # Batch_size, rnn_units. When return_sequence = true, shape = N, input_shape, rnn_units. (useful for stacking RNN)\n",
    "#                 tf.keras.layers.LSTM(32, return_sequences=False),\n",
    "#                 tf.keras.layers.Dense(1),\n",
    "#             ]\n",
    "#         )\n",
    "# model.compile(\n",
    "#     optimizer=tf.keras.optimizers.RMSprop(),\n",
    "#     loss=tf.keras.losses.MeanSquaredError(),\n",
    "#     metrics=[\n",
    "#         tf.keras.metrics.mean_squared_error,\n",
    "#         tf.keras.metrics.mean_absolute_error,\n",
    "#     ],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowGenerator:\n",
    "    def __init__(\n",
    "        self, lookback, lookahead, batch_size, train_df, test_df, label_column\n",
    "    ):\n",
    "        # Your code here\n",
    "        # Store data\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        # Get the column indices\n",
    "        self.label_column = label_column\n",
    "        self.label_column_indices = {\n",
    "            name: i for i, name in enumerate(label_column)\n",
    "        }  # Encoding column name into index\n",
    "        self.column_indices = {name: i for i, name in enumerate(self.train_df.columns)}\n",
    "\n",
    "        # Window parameters\n",
    "        self.lookback = lookback\n",
    "        self.lookahead = lookahead\n",
    "        self.total_window_size = self.lookback + self.lookahead\n",
    "        self.input_slice = slice(0, self.lookback)\n",
    "        self.lookback_idx = np.arange(self.total_window_size)[self.input_slice]\n",
    "        self.label_start = self.total_window_size - self.lookahead\n",
    "        self.label_slice = slice(self.label_start, None)\n",
    "        self.label_idx = np.arange(self.total_window_size)[self.label_slice]\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"\\n\".join(\n",
    "            [\n",
    "                f\"Total window size: {self.total_window_size}\",\n",
    "                f\"Lookback indices: {self.lookback_idx}\",\n",
    "                f\"Label index: {self.label_idx}\",\n",
    "                f\"Label name: {self.label_column}\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def train(self):\n",
    "        return self.make_dataset(self.train_df)\n",
    "\n",
    "\n",
    "    @property\n",
    "    def test(self):\n",
    "        return self.make_dataset(self.test_df, shuffle=False)\n",
    "\n",
    "    def make_dataset(self, data, shuffle=True):\n",
    "        # Your code here\n",
    "        data = np.array(data, dtype=np.float32)\n",
    "        ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "            data=data,\n",
    "            targets=None,\n",
    "            sequence_length=self.total_window_size,\n",
    "            sequence_stride=1,\n",
    "            shuffle=shuffle,\n",
    "            batch_size=32,\n",
    "        )\n",
    "\n",
    "        ds = ds.map(self.split_window)\n",
    "\n",
    "        return ds\n",
    "\n",
    "    def split_window(self, features):\n",
    "        inputs = features[:, self.input_slice, :]\n",
    "        labels = features[:, self.label_slice, :]\n",
    "        labels = tf.stack(\n",
    "            [labels[:, :, self.column_indices[name]] for name in self.label_column],\n",
    "            axis=-1,\n",
    "        )\n",
    "        inputs.set_shape([None, self.lookback, None])\n",
    "        labels.set_shape([None, self.lookahead, None])\n",
    "\n",
    "        return inputs, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = X_train_trans\n",
    "train_1['Date'] = train.Date\n",
    "train_1['Weekly_Sales'] = np.exp(y_train)\n",
    "train_1 = train_1.set_index(['Date'])\n",
    "train_1 = train_1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = X_test_trans\n",
    "test_1['Date'] = test.Date\n",
    "test_1['Weekly_Sales'] = np.exp(y_test)\n",
    "test_1 = test_1.set_index(['Date'])\n",
    "test_1 = test_1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>MarkDown4</th>\n",
       "      <th>MarkDown5</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Weekly_sales_lag</th>\n",
       "      <th>IsHoliday_False</th>\n",
       "      <th>...</th>\n",
       "      <th>week_44</th>\n",
       "      <th>week_45</th>\n",
       "      <th>week_46</th>\n",
       "      <th>week_47</th>\n",
       "      <th>week_48</th>\n",
       "      <th>week_49</th>\n",
       "      <th>week_50</th>\n",
       "      <th>week_51</th>\n",
       "      <th>week_52</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-02-05</th>\n",
       "      <td>-0.953080</td>\n",
       "      <td>-1.702558</td>\n",
       "      <td>-0.419353</td>\n",
       "      <td>-0.175588</td>\n",
       "      <td>-0.085799</td>\n",
       "      <td>-0.274567</td>\n",
       "      <td>-0.380216</td>\n",
       "      <td>1.023768</td>\n",
       "      <td>0.906984</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32229.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-05</th>\n",
       "      <td>-0.953080</td>\n",
       "      <td>-1.702558</td>\n",
       "      <td>-0.419353</td>\n",
       "      <td>-0.175588</td>\n",
       "      <td>-0.085799</td>\n",
       "      <td>-0.274567</td>\n",
       "      <td>-0.380216</td>\n",
       "      <td>1.023768</td>\n",
       "      <td>0.066282</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5749.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-05</th>\n",
       "      <td>-0.953080</td>\n",
       "      <td>-1.702558</td>\n",
       "      <td>-0.419353</td>\n",
       "      <td>-0.175588</td>\n",
       "      <td>-0.085799</td>\n",
       "      <td>-0.274567</td>\n",
       "      <td>-0.380216</td>\n",
       "      <td>1.023768</td>\n",
       "      <td>0.700028</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21084.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-05</th>\n",
       "      <td>-0.953080</td>\n",
       "      <td>-1.702558</td>\n",
       "      <td>-0.419353</td>\n",
       "      <td>-0.175588</td>\n",
       "      <td>-0.085799</td>\n",
       "      <td>-0.274567</td>\n",
       "      <td>-0.380216</td>\n",
       "      <td>1.023768</td>\n",
       "      <td>1.013896</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40129.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-05</th>\n",
       "      <td>-0.953080</td>\n",
       "      <td>-1.702558</td>\n",
       "      <td>-0.419353</td>\n",
       "      <td>-0.175588</td>\n",
       "      <td>-0.085799</td>\n",
       "      <td>-0.274567</td>\n",
       "      <td>-0.380216</td>\n",
       "      <td>1.023768</td>\n",
       "      <td>0.593042</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16930.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-28</th>\n",
       "      <td>0.258408</td>\n",
       "      <td>1.429542</td>\n",
       "      <td>0.325591</td>\n",
       "      <td>-0.171579</td>\n",
       "      <td>-0.085531</td>\n",
       "      <td>0.131404</td>\n",
       "      <td>0.398139</td>\n",
       "      <td>0.535703</td>\n",
       "      <td>0.273228</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8787.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-28</th>\n",
       "      <td>0.258408</td>\n",
       "      <td>1.429542</td>\n",
       "      <td>0.325591</td>\n",
       "      <td>-0.171579</td>\n",
       "      <td>-0.085531</td>\n",
       "      <td>0.131404</td>\n",
       "      <td>0.398139</td>\n",
       "      <td>0.535703</td>\n",
       "      <td>0.733156</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22566.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-28</th>\n",
       "      <td>0.258408</td>\n",
       "      <td>1.429542</td>\n",
       "      <td>0.325591</td>\n",
       "      <td>-0.171579</td>\n",
       "      <td>-0.085531</td>\n",
       "      <td>0.131404</td>\n",
       "      <td>0.398139</td>\n",
       "      <td>0.535703</td>\n",
       "      <td>0.534664</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15020.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-28</th>\n",
       "      <td>0.258408</td>\n",
       "      <td>1.429542</td>\n",
       "      <td>0.325591</td>\n",
       "      <td>-0.171579</td>\n",
       "      <td>-0.085531</td>\n",
       "      <td>0.131404</td>\n",
       "      <td>0.398139</td>\n",
       "      <td>0.535703</td>\n",
       "      <td>1.094820</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47372.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-28</th>\n",
       "      <td>0.258408</td>\n",
       "      <td>1.429542</td>\n",
       "      <td>0.325591</td>\n",
       "      <td>-0.171579</td>\n",
       "      <td>-0.085531</td>\n",
       "      <td>0.131404</td>\n",
       "      <td>0.398139</td>\n",
       "      <td>0.535703</td>\n",
       "      <td>-0.291051</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2763.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>408361 rows × 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Temperature  Fuel_Price  MarkDown1  MarkDown2  MarkDown3  \\\n",
       "Date                                                                   \n",
       "2010-02-05    -0.953080   -1.702558  -0.419353  -0.175588  -0.085799   \n",
       "2010-02-05    -0.953080   -1.702558  -0.419353  -0.175588  -0.085799   \n",
       "2010-02-05    -0.953080   -1.702558  -0.419353  -0.175588  -0.085799   \n",
       "2010-02-05    -0.953080   -1.702558  -0.419353  -0.175588  -0.085799   \n",
       "2010-02-05    -0.953080   -1.702558  -0.419353  -0.175588  -0.085799   \n",
       "...                 ...         ...        ...        ...        ...   \n",
       "2012-09-28     0.258408    1.429542   0.325591  -0.171579  -0.085531   \n",
       "2012-09-28     0.258408    1.429542   0.325591  -0.171579  -0.085531   \n",
       "2012-09-28     0.258408    1.429542   0.325591  -0.171579  -0.085531   \n",
       "2012-09-28     0.258408    1.429542   0.325591  -0.171579  -0.085531   \n",
       "2012-09-28     0.258408    1.429542   0.325591  -0.171579  -0.085531   \n",
       "\n",
       "            MarkDown4  MarkDown5       CPI  Weekly_sales_lag  IsHoliday_False  \\\n",
       "Date                                                                            \n",
       "2010-02-05  -0.274567  -0.380216  1.023768          0.906984              1.0   \n",
       "2010-02-05  -0.274567  -0.380216  1.023768          0.066282              1.0   \n",
       "2010-02-05  -0.274567  -0.380216  1.023768          0.700028              1.0   \n",
       "2010-02-05  -0.274567  -0.380216  1.023768          1.013896              1.0   \n",
       "2010-02-05  -0.274567  -0.380216  1.023768          0.593042              1.0   \n",
       "...               ...        ...       ...               ...              ...   \n",
       "2012-09-28   0.131404   0.398139  0.535703          0.273228              1.0   \n",
       "2012-09-28   0.131404   0.398139  0.535703          0.733156              1.0   \n",
       "2012-09-28   0.131404   0.398139  0.535703          0.534664              1.0   \n",
       "2012-09-28   0.131404   0.398139  0.535703          1.094820              1.0   \n",
       "2012-09-28   0.131404   0.398139  0.535703         -0.291051              1.0   \n",
       "\n",
       "            ...  week_44  week_45  week_46  week_47  week_48  week_49  \\\n",
       "Date        ...                                                         \n",
       "2010-02-05  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2010-02-05  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2010-02-05  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2010-02-05  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2010-02-05  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "...         ...      ...      ...      ...      ...      ...      ...   \n",
       "2012-09-28  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2012-09-28  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2012-09-28  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2012-09-28  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2012-09-28  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "            week_50  week_51  week_52  Weekly_Sales  \n",
       "Date                                                 \n",
       "2010-02-05      0.0      0.0      0.0      32229.38  \n",
       "2010-02-05      0.0      0.0      0.0       5749.03  \n",
       "2010-02-05      0.0      0.0      0.0      21084.08  \n",
       "2010-02-05      0.0      0.0      0.0      40129.01  \n",
       "2010-02-05      0.0      0.0      0.0      16930.99  \n",
       "...             ...      ...      ...           ...  \n",
       "2012-09-28      0.0      0.0      0.0       8787.85  \n",
       "2012-09-28      0.0      0.0      0.0      22566.07  \n",
       "2012-09-28      0.0      0.0      0.0      15020.88  \n",
       "2012-09-28      0.0      0.0      0.0      47372.08  \n",
       "2012-09-28      0.0      0.0      0.0       2763.02  \n",
       "\n",
       "[408361 rows x 118 columns]"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = WindowGenerator(lookback=6, lookahead=1, batch_size=100, train_df=train_1, test_df=test_1, label_column=['Weekly_Sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-15 19:47:33.820622: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-12-15 19:47:34.263221: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-12-15 19:47:34.461087: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12762/12762 [==============================] - 316s 25ms/step - loss: 548226752.0000 - mean_squared_error: 548226752.0000 - mean_absolute_error: 14161.3799\n",
      "Epoch 2/10\n",
      "12762/12762 [==============================] - 309s 24ms/step - loss: 513250464.0000 - mean_squared_error: 513250464.0000 - mean_absolute_error: 14836.7119\n",
      "Epoch 3/10\n",
      "12762/12762 [==============================] - 309s 24ms/step - loss: 509858432.0000 - mean_squared_error: 509858432.0000 - mean_absolute_error: 14832.7061\n",
      "Epoch 4/10\n",
      "12762/12762 [==============================] - 297s 23ms/step - loss: 506764416.0000 - mean_squared_error: 506764416.0000 - mean_absolute_error: 14801.3369\n",
      "Epoch 5/10\n",
      "12762/12762 [==============================] - 277s 22ms/step - loss: 504896800.0000 - mean_squared_error: 504896800.0000 - mean_absolute_error: 14738.3281\n",
      "Epoch 6/10\n",
      "12762/12762 [==============================] - 276s 22ms/step - loss: 502511040.0000 - mean_squared_error: 502511040.0000 - mean_absolute_error: 14672.1738\n",
      "Epoch 7/10\n",
      "12762/12762 [==============================] - 290s 23ms/step - loss: 494121120.0000 - mean_squared_error: 494121120.0000 - mean_absolute_error: 14521.0918\n",
      "Epoch 8/10\n",
      "12762/12762 [==============================] - 283s 22ms/step - loss: 492279328.0000 - mean_squared_error: 492279328.0000 - mean_absolute_error: 14441.8682\n",
      "Epoch 9/10\n",
      "12762/12762 [==============================] - 267s 21ms/step - loss: 483961856.0000 - mean_squared_error: 483961856.0000 - mean_absolute_error: 14287.8340\n",
      "Epoch 10/10\n",
      "12762/12762 [==============================] - 275s 22ms/step - loss: 479587232.0000 - mean_squared_error: 479587232.0000 - mean_absolute_error: 14213.9961\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(w1.train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1/12762 [..............................] - ETA: 1:41:54"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-15 17:16:31.169802: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-12-15 17:16:31.270068: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12762/12762 [==============================] - 75s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(w1.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.765172022365282"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(train_1['Weekly_Sales'][6:], pred.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7353736499240329"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(model.evaluate(w1.train)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7669559121447977"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(model.evaluate(w1.test)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 3s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(w1.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0154105598483505"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(test_1['Weekly_Sales'][6:], pred.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Train RMSE | Test RMSE |\n",
    "|------|-------------|-----------|\n",
    "| Logistic Regression | 1.90 | 1.86 | \n",
    "| RandomForest Regressor | 0.76 | 1.76 |\n",
    "| Neural Network | 0.73 | 0.76 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASIC NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408365, 119)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(2000, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(500, activation='relu'),\n",
    "    tf.keras.layers.Dense(250, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='relu'),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.RMSprop(),\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.mean_squared_error,\n",
    "        tf.keras.metrics.mean_absolute_error,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() got an unexpected keyword argument 'epoch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [397], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mfit(tf\u001b[39m.\u001b[39;49mconvert_to_tensor(np\u001b[39m.\u001b[39;49marray(X_train_trans)\u001b[39m.\u001b[39;49mastype(\u001b[39m'\u001b[39;49m\u001b[39mfloat32\u001b[39;49m\u001b[39m'\u001b[39;49m)), tf\u001b[39m.\u001b[39;49mconvert_to_tensor(np\u001b[39m.\u001b[39;49marray(y_train)\u001b[39m.\u001b[39;49mastype(\u001b[39m'\u001b[39;49m\u001b[39mfloat32\u001b[39;49m\u001b[39m'\u001b[39;49m)), epoch \u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniforge3/envs/assignment-5-tensor/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniforge3/envs/assignment-5-tensor/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "\u001b[0;31mTypeError\u001b[0m: fit() got an unexpected keyword argument 'epoch'"
     ]
    }
   ],
   "source": [
    "model.fit(tf.convert_to_tensor(np.array(X_train_trans).astype('float32')), tf.convert_to_tensor(np.array(y_train).astype('float32')), epoch =10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(<408365x117 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 7350570 stored elements in Compressed Sparse Row format>,\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.95308024, -1.7025583 , -0.4193528 , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.95308024, -1.7025583 , -0.4193528 , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.95308024, -1.7025583 , -0.4193528 , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.2584079 ,  1.4295418 ,  0.3255911 , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.2584079 ,  1.4295418 ,  0.3255911 , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.2584079 ,  1.4295418 ,  0.3255911 , ...,  0.        ,\n",
       "         0.        ,  0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_train_trans).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('assignment-5-tensor')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f7b906d99b2ec91f843337fb9b0616c07f4c02a7a501f2516fb446e3b496cbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
