{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>...</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Size</th>\n",
       "      <th>Super_Bowl</th>\n",
       "      <th>Labor_Day</th>\n",
       "      <th>Thanksgiving</th>\n",
       "      <th>Christmas</th>\n",
       "      <th>week</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>24924.50</td>\n",
       "      <td>False</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>50605.27</td>\n",
       "      <td>False</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>13740.12</td>\n",
       "      <td>False</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>39954.04</td>\n",
       "      <td>False</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>32229.38</td>\n",
       "      <td>False</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  Dept        Date  Weekly_Sales  IsHoliday  Temperature  Fuel_Price  \\\n",
       "0      1     1  2010-02-05      24924.50      False        42.31       2.572   \n",
       "1      1     2  2010-02-05      50605.27      False        42.31       2.572   \n",
       "2      1     3  2010-02-05      13740.12      False        42.31       2.572   \n",
       "3      1     4  2010-02-05      39954.04      False        42.31       2.572   \n",
       "4      1     5  2010-02-05      32229.38      False        42.31       2.572   \n",
       "\n",
       "   MarkDown1  MarkDown2  MarkDown3  ...  Unemployment  Type    Size  \\\n",
       "0        0.0        0.0        0.0  ...         8.106     A  151315   \n",
       "1        0.0        0.0        0.0  ...         8.106     A  151315   \n",
       "2        0.0        0.0        0.0  ...         8.106     A  151315   \n",
       "3        0.0        0.0        0.0  ...         8.106     A  151315   \n",
       "4        0.0        0.0        0.0  ...         8.106     A  151315   \n",
       "\n",
       "   Super_Bowl Labor_Day  Thanksgiving  Christmas  week  month  year  \n",
       "0       False     False         False      False     5      2  2010  \n",
       "1       False     False         False      False     5      2  2010  \n",
       "2       False     False         False      False     5      2  2010  \n",
       "3       False     False         False      False     5      2  2010  \n",
       "4       False     False         False      False     5      2  2010  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/raw/clean_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1q/26x3nv656dg2gv4xzbytws5m0000gn/T/ipykernel_35779/691307098.py:6: FutureWarning: Value based partial slicing on non-monotonic DatetimeIndexes with non-existing keys is deprecated and will raise a KeyError in a future Version.\n",
      "  test = df.loc['2012-10-01':].reset_index()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((408369, 23), (11843, 23))"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Date'] = pd.to_datetime(df[\"Date\"])\n",
    "df.index = df['Date']\n",
    "df = df.drop(['Date'], axis=1)\n",
    "df['Weekly_Sales'] = np.log(df['Weekly_Sales'])\n",
    "train = df.loc[:'2012-10-01'].reset_index()\n",
    "test = df.loc['2012-10-01':].reset_index()\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.set_index(\"Date\")\n",
    "train['Weekly_sales_lag'] = train['Weekly_Sales'].shift(4)\n",
    "train = train.reset_index()\n",
    "train = train.dropna()\n",
    "\n",
    "test = test.set_index(\"Date\")\n",
    "test['Weekly_sales_lag'] = test['Weekly_Sales'].shift(4)\n",
    "test = test.reset_index()\n",
    "test = test.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['Weekly_Sales'], axis=1)\n",
    "y_train = train['Weekly_Sales']\n",
    "\n",
    "X_test = test.drop(['Weekly_Sales'], axis=1)\n",
    "y_test = test['Weekly_Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train['Date'] = pd.to_datetime(X_train['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Store', 'Dept', 'IsHoliday', 'Temperature', 'Fuel_Price',\n",
       "       'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI',\n",
       "       'Unemployment', 'Type', 'Size', 'Super_Bowl', 'Labor_Day',\n",
       "       'Thanksgiving', 'Christmas', 'week', 'month', 'year',\n",
       "       'Weekly_sales_lag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_FEATURE_KEYS = [\n",
    "    # 'Dept',\n",
    "    'IsHoliday',\n",
    "    \"Super_Bowl\",\n",
    "    \"Type\",\n",
    "    \"Size\",\n",
    "    \"Labor_Day\",\n",
    "    \"Thanksgiving\",\n",
    "    \"Christmas\",\n",
    "    \"year\",\n",
    "    \"week\"\n",
    "]\n",
    "\n",
    "NUMERIC_FEATURE_KEYS = [\n",
    "    \"Temperature\",\n",
    "    \"Fuel_Price\",\n",
    "    \"MarkDown1\",\n",
    "    \"MarkDown2\",\n",
    "    \"MarkDown3\",\n",
    "    \"MarkDown4\",\n",
    "    \"MarkDown5\",\n",
    "    \"CPI\",\n",
    "    \"Weekly_sales_lag\"\n",
    "]\n",
    "\n",
    "# ORDINAL_FEATURE_KEYS = [\n",
    "#     \"year\",\n",
    "#     \"week\"\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(\n",
    "    [(\"Numeric\", StandardScaler(), NUMERIC_FEATURE_KEYS),\n",
    "     (\"Categorical\", OneHotEncoder(), CATEGORICAL_FEATURE_KEYS)\n",
    "    ])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[('preprocessor', ct)])\n",
    "X_train_trans = ct.fit_transform(X_train)\n",
    "X_test_trans = ct.transform(X_test)\n",
    "trans_col = pipeline.named_steps['preprocessor'].transformers_[1][1].get_feature_names_out(CATEGORICAL_FEATURE_KEYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trans = pd.DataFrame(X_train_trans.toarray(), columns=NUMERIC_FEATURE_KEYS + trans_col.tolist())\n",
    "X_test_trans = pd.DataFrame(X_test_trans.toarray(),columns=NUMERIC_FEATURE_KEYS + trans_col.tolist())\n",
    "# X_train_trans['week'] = X_train['week']\n",
    "# X_test_trans['week'] = X_test['week']\n",
    "# X_train_trans = X_train_trans.dropna()\n",
    "# X_test_trans = X_test_trans.dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>MarkDown4</th>\n",
       "      <th>MarkDown5</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Weekly_sales_lag</th>\n",
       "      <th>IsHoliday_False</th>\n",
       "      <th>...</th>\n",
       "      <th>week_43</th>\n",
       "      <th>week_44</th>\n",
       "      <th>week_45</th>\n",
       "      <th>week_46</th>\n",
       "      <th>week_47</th>\n",
       "      <th>week_48</th>\n",
       "      <th>week_49</th>\n",
       "      <th>week_50</th>\n",
       "      <th>week_51</th>\n",
       "      <th>week_52</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.953080</td>\n",
       "      <td>-1.702558</td>\n",
       "      <td>-0.419353</td>\n",
       "      <td>-0.175588</td>\n",
       "      <td>-0.085799</td>\n",
       "      <td>-0.274567</td>\n",
       "      <td>-0.380216</td>\n",
       "      <td>1.023768</td>\n",
       "      <td>0.781635</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.953080</td>\n",
       "      <td>-1.702558</td>\n",
       "      <td>-0.419353</td>\n",
       "      <td>-0.175588</td>\n",
       "      <td>-0.085799</td>\n",
       "      <td>-0.274567</td>\n",
       "      <td>-0.380216</td>\n",
       "      <td>1.023768</td>\n",
       "      <td>1.127018</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.953080</td>\n",
       "      <td>-1.702558</td>\n",
       "      <td>-0.419353</td>\n",
       "      <td>-0.175588</td>\n",
       "      <td>-0.085799</td>\n",
       "      <td>-0.274567</td>\n",
       "      <td>-0.380216</td>\n",
       "      <td>1.023768</td>\n",
       "      <td>0.491200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.953080</td>\n",
       "      <td>-1.702558</td>\n",
       "      <td>-0.419353</td>\n",
       "      <td>-0.175588</td>\n",
       "      <td>-0.085799</td>\n",
       "      <td>-0.274567</td>\n",
       "      <td>-0.380216</td>\n",
       "      <td>1.023768</td>\n",
       "      <td>1.011765</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.953080</td>\n",
       "      <td>-1.702558</td>\n",
       "      <td>-0.419353</td>\n",
       "      <td>-0.175588</td>\n",
       "      <td>-0.085799</td>\n",
       "      <td>-0.274567</td>\n",
       "      <td>-0.380216</td>\n",
       "      <td>1.023768</td>\n",
       "      <td>0.906984</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408360</th>\n",
       "      <td>0.258408</td>\n",
       "      <td>1.429542</td>\n",
       "      <td>0.325591</td>\n",
       "      <td>-0.171579</td>\n",
       "      <td>-0.085531</td>\n",
       "      <td>0.131404</td>\n",
       "      <td>0.398139</td>\n",
       "      <td>0.535703</td>\n",
       "      <td>0.273228</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408361</th>\n",
       "      <td>0.258408</td>\n",
       "      <td>1.429542</td>\n",
       "      <td>0.325591</td>\n",
       "      <td>-0.171579</td>\n",
       "      <td>-0.085531</td>\n",
       "      <td>0.131404</td>\n",
       "      <td>0.398139</td>\n",
       "      <td>0.535703</td>\n",
       "      <td>0.733156</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408362</th>\n",
       "      <td>0.258408</td>\n",
       "      <td>1.429542</td>\n",
       "      <td>0.325591</td>\n",
       "      <td>-0.171579</td>\n",
       "      <td>-0.085531</td>\n",
       "      <td>0.131404</td>\n",
       "      <td>0.398139</td>\n",
       "      <td>0.535703</td>\n",
       "      <td>0.534664</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408363</th>\n",
       "      <td>0.258408</td>\n",
       "      <td>1.429542</td>\n",
       "      <td>0.325591</td>\n",
       "      <td>-0.171579</td>\n",
       "      <td>-0.085531</td>\n",
       "      <td>0.131404</td>\n",
       "      <td>0.398139</td>\n",
       "      <td>0.535703</td>\n",
       "      <td>1.094820</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408364</th>\n",
       "      <td>0.258408</td>\n",
       "      <td>1.429542</td>\n",
       "      <td>0.325591</td>\n",
       "      <td>-0.171579</td>\n",
       "      <td>-0.085531</td>\n",
       "      <td>0.131404</td>\n",
       "      <td>0.398139</td>\n",
       "      <td>0.535703</td>\n",
       "      <td>-0.291051</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>408365 rows Ã— 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Temperature  Fuel_Price  MarkDown1  MarkDown2  MarkDown3  MarkDown4  \\\n",
       "0         -0.953080   -1.702558  -0.419353  -0.175588  -0.085799  -0.274567   \n",
       "1         -0.953080   -1.702558  -0.419353  -0.175588  -0.085799  -0.274567   \n",
       "2         -0.953080   -1.702558  -0.419353  -0.175588  -0.085799  -0.274567   \n",
       "3         -0.953080   -1.702558  -0.419353  -0.175588  -0.085799  -0.274567   \n",
       "4         -0.953080   -1.702558  -0.419353  -0.175588  -0.085799  -0.274567   \n",
       "...             ...         ...        ...        ...        ...        ...   \n",
       "408360     0.258408    1.429542   0.325591  -0.171579  -0.085531   0.131404   \n",
       "408361     0.258408    1.429542   0.325591  -0.171579  -0.085531   0.131404   \n",
       "408362     0.258408    1.429542   0.325591  -0.171579  -0.085531   0.131404   \n",
       "408363     0.258408    1.429542   0.325591  -0.171579  -0.085531   0.131404   \n",
       "408364     0.258408    1.429542   0.325591  -0.171579  -0.085531   0.131404   \n",
       "\n",
       "        MarkDown5       CPI  Weekly_sales_lag  IsHoliday_False  ...  week_43  \\\n",
       "0       -0.380216  1.023768          0.781635              1.0  ...      0.0   \n",
       "1       -0.380216  1.023768          1.127018              1.0  ...      0.0   \n",
       "2       -0.380216  1.023768          0.491200              1.0  ...      0.0   \n",
       "3       -0.380216  1.023768          1.011765              1.0  ...      0.0   \n",
       "4       -0.380216  1.023768          0.906984              1.0  ...      0.0   \n",
       "...           ...       ...               ...              ...  ...      ...   \n",
       "408360   0.398139  0.535703          0.273228              1.0  ...      0.0   \n",
       "408361   0.398139  0.535703          0.733156              1.0  ...      0.0   \n",
       "408362   0.398139  0.535703          0.534664              1.0  ...      0.0   \n",
       "408363   0.398139  0.535703          1.094820              1.0  ...      0.0   \n",
       "408364   0.398139  0.535703         -0.291051              1.0  ...      0.0   \n",
       "\n",
       "        week_44  week_45  week_46  week_47  week_48  week_49  week_50  \\\n",
       "0           0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1           0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2           0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3           0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4           0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "...         ...      ...      ...      ...      ...      ...      ...   \n",
       "408360      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "408361      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "408362      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "408363      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "408364      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "        week_51  week_52  \n",
       "0           0.0      0.0  \n",
       "1           0.0      0.0  \n",
       "2           0.0      0.0  \n",
       "3           0.0      0.0  \n",
       "4           0.0      0.0  \n",
       "...         ...      ...  \n",
       "408360      0.0      0.0  \n",
       "408361      0.0      0.0  \n",
       "408362      0.0      0.0  \n",
       "408363      0.0      0.0  \n",
       "408364      0.0      0.0  \n",
       "\n",
       "[408365 rows x 117 columns]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((408365, 117),\n",
       " Index(['Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3',\n",
       "        'MarkDown4', 'MarkDown5', 'CPI', 'Weekly_sales_lag', 'IsHoliday_False',\n",
       "        ...\n",
       "        'week_43', 'week_44', 'week_45', 'week_46', 'week_47', 'week_48',\n",
       "        'week_49', 'week_50', 'week_51', 'week_52'],\n",
       "       dtype='object', length=117))"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_trans.shape, X_train_trans.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['IsHoliday_False', 'IsHoliday_True', 'Super_Bowl_False',\n",
       "       'Super_Bowl_True', 'Type_A', 'Type_B', 'Type_C', 'Size_34875',\n",
       "       'Size_37392', 'Size_39690', 'Size_39910', 'Size_41062',\n",
       "       'Size_42988', 'Size_57197', 'Size_70713', 'Size_93188',\n",
       "       'Size_93638', 'Size_103681', 'Size_112238', 'Size_114533',\n",
       "       'Size_118221', 'Size_119557', 'Size_120653', 'Size_123737',\n",
       "       'Size_125833', 'Size_126512', 'Size_128107', 'Size_140167',\n",
       "       'Size_151315', 'Size_152513', 'Size_155078', 'Size_155083',\n",
       "       'Size_158114', 'Size_184109', 'Size_196321', 'Size_200898',\n",
       "       'Size_202307', 'Size_202505', 'Size_203007', 'Size_203742',\n",
       "       'Size_203750', 'Size_203819', 'Size_204184', 'Size_205863',\n",
       "       'Size_206302', 'Size_207499', 'Size_219622', 'Labor_Day_False',\n",
       "       'Labor_Day_True', 'Thanksgiving_False', 'Thanksgiving_True',\n",
       "       'Christmas_False', 'Christmas_True', 'year_2010', 'year_2011',\n",
       "       'year_2012', 'week_1', 'week_2', 'week_3', 'week_4', 'week_5',\n",
       "       'week_6', 'week_7', 'week_8', 'week_9', 'week_10', 'week_11',\n",
       "       'week_12', 'week_13', 'week_14', 'week_15', 'week_16', 'week_17',\n",
       "       'week_18', 'week_19', 'week_20', 'week_21', 'week_22', 'week_23',\n",
       "       'week_24', 'week_25', 'week_26', 'week_27', 'week_28', 'week_29',\n",
       "       'week_30', 'week_31', 'week_32', 'week_33', 'week_34', 'week_35',\n",
       "       'week_36', 'week_37', 'week_38', 'week_39', 'week_40', 'week_41',\n",
       "       'week_42', 'week_43', 'week_44', 'week_45', 'week_46', 'week_47',\n",
       "       'week_48', 'week_49', 'week_50', 'week_51', 'week_52'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train_trans, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lr = lr.predict(X_train_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.9049469796673701"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Train\")\n",
    "np.sqrt(mean_squared_error(y_train, pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.8262898697153267"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"test\")\n",
    "test_pred_lr = lr.predict(X_test_trans)\n",
    "np.sqrt(mean_squared_error(y_test, test_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-4.605170185988091, 12.169724223396777, 1.9976587043296536)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.min(), y_test.max(), y_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=50)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=50)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt = RandomForestRegressor(max_depth= 50)\n",
    "rt.fit(X_train_trans, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rt = rt.predict(X_train_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_rt = rt.predict(X_test_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7618383334851071"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_train, pred_rt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-4.605170185988091, 13.448928644517972, 2.050487503404155)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.min(), y_train.max(), y_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7663920528199546"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, test_pred_rt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-4.605170185988091, 12.169724223396777, 1.9976587043296536)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.min(), y_test.max(), y_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel:\n",
    "    def __init__(self, rnn_units=100, return_sequences=False):\n",
    "        # Your code here\n",
    "        self.model = tf.keras.Sequential(\n",
    "            [\n",
    "                # Batch_size, rnn_units. When return_sequence = true, shape = N, input_shape, rnn_units. (useful for stacking RNN)\n",
    "                tf.keras.layers.LSTM(rnn_units, return_sequences=return_sequences),\n",
    "                # tf.keras.layers.SimpleRNN(128),\n",
    "                tf.keras.layers.Dense(10),\n",
    "                tf.keras.layers.Dense(5),\n",
    "                tf.keras.layers.Dense(1),\n",
    "                tf.keras.layers.Dense(1, activation='linear'),\n",
    "            ]\n",
    "        )\n",
    "        self.model.compile(\n",
    "            optimizer=tf.keras.optimizers.RMSprop(),\n",
    "            loss=tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[\n",
    "                tf.keras.metrics.mean_squared_error,\n",
    "                tf.keras.metrics.mean_absolute_error,\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    def fit(self, train_data, epochs, val_data=None, callbacks=None):\n",
    "        # Your code here\n",
    "        history = self.model.fit(\n",
    "            train_data, epochs=epochs, validation_data=val_data, callbacks=callbacks\n",
    "        )\n",
    "        return history\n",
    "\n",
    "    def evaluate(self, eval_data, verbose=0):\n",
    "        # Your code here\n",
    "        result = self.model.evaluate(eval_data, verbose=verbose, return_dict=True)\n",
    "        return result['mean_squared_error'], result['mean_absolute_error']\n",
    "\n",
    "    def predict(self, pred_data):\n",
    "        # Your code here\n",
    "        return self.model.predict(pred_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.Sequential(\n",
    "#             [\n",
    "#                 # Batch_size, rnn_units. When return_sequence = true, shape = N, input_shape, rnn_units. (useful for stacking RNN)\n",
    "#                 tf.keras.layers.LSTM(32, return_sequences=False),\n",
    "#                 tf.keras.layers.Dense(1),\n",
    "#             ]\n",
    "#         )\n",
    "# model.compile(\n",
    "#     optimizer=tf.keras.optimizers.RMSprop(),\n",
    "#     loss=tf.keras.losses.MeanSquaredError(),\n",
    "#     metrics=[\n",
    "#         tf.keras.metrics.mean_squared_error,\n",
    "#         tf.keras.metrics.mean_absolute_error,\n",
    "#     ],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowGenerator:\n",
    "    def __init__(\n",
    "        self, lookback, lookahead, batch_size, train_df, test_df, label_column\n",
    "    ):\n",
    "        # Your code here\n",
    "        # Store data\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        # Get the column indices\n",
    "        self.label_column = label_column\n",
    "        self.label_column_indices = {\n",
    "            name: i for i, name in enumerate(label_column)\n",
    "        }  # Encoding column name into index\n",
    "        self.column_indices = {name: i for i, name in enumerate(self.train_df.columns)}\n",
    "\n",
    "        # Window parameters\n",
    "        self.lookback = lookback\n",
    "        self.lookahead = lookahead\n",
    "        self.total_window_size = self.lookback + self.lookahead\n",
    "        self.input_slice = slice(0, self.lookback)\n",
    "        self.lookback_idx = np.arange(self.total_window_size)[self.input_slice]\n",
    "        self.label_start = self.total_window_size - self.lookahead\n",
    "        self.label_slice = slice(self.label_start, None)\n",
    "        self.label_idx = np.arange(self.total_window_size)[self.label_slice]\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"\\n\".join(\n",
    "            [\n",
    "                f\"Total window size: {self.total_window_size}\",\n",
    "                f\"Lookback indices: {self.lookback_idx}\",\n",
    "                f\"Label index: {self.label_idx}\",\n",
    "                f\"Label name: {self.label_column}\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def train(self):\n",
    "        return self.make_dataset(self.train_df)\n",
    "\n",
    "\n",
    "    @property\n",
    "    def test(self):\n",
    "        return self.make_dataset(self.test_df, shuffle=False)\n",
    "\n",
    "    def make_dataset(self, data, shuffle=True):\n",
    "        # Your code here\n",
    "        data = np.array(data, dtype=np.float32)\n",
    "        ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "            data=data,\n",
    "            targets=None,\n",
    "            sequence_length=self.total_window_size,\n",
    "            sequence_stride=1,\n",
    "            shuffle=shuffle,\n",
    "            batch_size=32,\n",
    "        )\n",
    "\n",
    "        ds = ds.map(self.split_window)\n",
    "\n",
    "        return ds\n",
    "\n",
    "    def split_window(self, features):\n",
    "        inputs = features[:, self.input_slice, :]\n",
    "        labels = features[:, self.label_slice, :]\n",
    "        labels = tf.stack(\n",
    "            [labels[:, :, self.column_indices[name]] for name in self.label_column],\n",
    "            axis=-1,\n",
    "        )\n",
    "        inputs.set_shape([None, self.lookback, None])\n",
    "        labels.set_shape([None, self.lookahead, None])\n",
    "\n",
    "        return inputs, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = X_train_trans\n",
    "train_1['Date'] = train.Date\n",
    "train_1['Weekly_Sales'] = y_train\n",
    "train_1 = train_1.set_index(['Date'])\n",
    "train_1 = train_1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = X_test_trans\n",
    "test_1['Date'] = test.Date\n",
    "test_1['Weekly_Sales'] = y_test\n",
    "test_1 = test_1.set_index(['Date'])\n",
    "test_1 = test_1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>MarkDown4</th>\n",
       "      <th>MarkDown5</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Weekly_sales_lag</th>\n",
       "      <th>IsHoliday_False</th>\n",
       "      <th>...</th>\n",
       "      <th>week_44</th>\n",
       "      <th>week_45</th>\n",
       "      <th>week_46</th>\n",
       "      <th>week_47</th>\n",
       "      <th>week_48</th>\n",
       "      <th>week_49</th>\n",
       "      <th>week_50</th>\n",
       "      <th>week_51</th>\n",
       "      <th>week_52</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-02-05</th>\n",
       "      <td>-0.953080</td>\n",
       "      <td>-1.702558</td>\n",
       "      <td>-0.419353</td>\n",
       "      <td>-0.175588</td>\n",
       "      <td>-0.085799</td>\n",
       "      <td>-0.274567</td>\n",
       "      <td>-0.380216</td>\n",
       "      <td>1.023768</td>\n",
       "      <td>0.906984</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.380634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-05</th>\n",
       "      <td>-0.953080</td>\n",
       "      <td>-1.702558</td>\n",
       "      <td>-0.419353</td>\n",
       "      <td>-0.175588</td>\n",
       "      <td>-0.085799</td>\n",
       "      <td>-0.274567</td>\n",
       "      <td>-0.380216</td>\n",
       "      <td>1.023768</td>\n",
       "      <td>0.066282</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.656786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-05</th>\n",
       "      <td>-0.953080</td>\n",
       "      <td>-1.702558</td>\n",
       "      <td>-0.419353</td>\n",
       "      <td>-0.175588</td>\n",
       "      <td>-0.085799</td>\n",
       "      <td>-0.274567</td>\n",
       "      <td>-0.380216</td>\n",
       "      <td>1.023768</td>\n",
       "      <td>0.700028</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.956274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-05</th>\n",
       "      <td>-0.953080</td>\n",
       "      <td>-1.702558</td>\n",
       "      <td>-0.419353</td>\n",
       "      <td>-0.175588</td>\n",
       "      <td>-0.085799</td>\n",
       "      <td>-0.274567</td>\n",
       "      <td>-0.380216</td>\n",
       "      <td>1.023768</td>\n",
       "      <td>1.013896</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.599855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-05</th>\n",
       "      <td>-0.953080</td>\n",
       "      <td>-1.702558</td>\n",
       "      <td>-0.419353</td>\n",
       "      <td>-0.175588</td>\n",
       "      <td>-0.085799</td>\n",
       "      <td>-0.274567</td>\n",
       "      <td>-0.380216</td>\n",
       "      <td>1.023768</td>\n",
       "      <td>0.593042</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.736901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-28</th>\n",
       "      <td>0.258408</td>\n",
       "      <td>1.429542</td>\n",
       "      <td>0.325591</td>\n",
       "      <td>-0.171579</td>\n",
       "      <td>-0.085531</td>\n",
       "      <td>0.131404</td>\n",
       "      <td>0.398139</td>\n",
       "      <td>0.535703</td>\n",
       "      <td>0.273228</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.081125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-28</th>\n",
       "      <td>0.258408</td>\n",
       "      <td>1.429542</td>\n",
       "      <td>0.325591</td>\n",
       "      <td>-0.171579</td>\n",
       "      <td>-0.085531</td>\n",
       "      <td>0.131404</td>\n",
       "      <td>0.398139</td>\n",
       "      <td>0.535703</td>\n",
       "      <td>0.733156</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.024203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-28</th>\n",
       "      <td>0.258408</td>\n",
       "      <td>1.429542</td>\n",
       "      <td>0.325591</td>\n",
       "      <td>-0.171579</td>\n",
       "      <td>-0.085531</td>\n",
       "      <td>0.131404</td>\n",
       "      <td>0.398139</td>\n",
       "      <td>0.535703</td>\n",
       "      <td>0.534664</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.617197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-28</th>\n",
       "      <td>0.258408</td>\n",
       "      <td>1.429542</td>\n",
       "      <td>0.325591</td>\n",
       "      <td>-0.171579</td>\n",
       "      <td>-0.085531</td>\n",
       "      <td>0.131404</td>\n",
       "      <td>0.398139</td>\n",
       "      <td>0.535703</td>\n",
       "      <td>1.094820</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.765788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-28</th>\n",
       "      <td>0.258408</td>\n",
       "      <td>1.429542</td>\n",
       "      <td>0.325591</td>\n",
       "      <td>-0.171579</td>\n",
       "      <td>-0.085531</td>\n",
       "      <td>0.131404</td>\n",
       "      <td>0.398139</td>\n",
       "      <td>0.535703</td>\n",
       "      <td>-0.291051</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.924080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>408361 rows Ã— 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Temperature  Fuel_Price  MarkDown1  MarkDown2  MarkDown3  \\\n",
       "Date                                                                   \n",
       "2010-02-05    -0.953080   -1.702558  -0.419353  -0.175588  -0.085799   \n",
       "2010-02-05    -0.953080   -1.702558  -0.419353  -0.175588  -0.085799   \n",
       "2010-02-05    -0.953080   -1.702558  -0.419353  -0.175588  -0.085799   \n",
       "2010-02-05    -0.953080   -1.702558  -0.419353  -0.175588  -0.085799   \n",
       "2010-02-05    -0.953080   -1.702558  -0.419353  -0.175588  -0.085799   \n",
       "...                 ...         ...        ...        ...        ...   \n",
       "2012-09-28     0.258408    1.429542   0.325591  -0.171579  -0.085531   \n",
       "2012-09-28     0.258408    1.429542   0.325591  -0.171579  -0.085531   \n",
       "2012-09-28     0.258408    1.429542   0.325591  -0.171579  -0.085531   \n",
       "2012-09-28     0.258408    1.429542   0.325591  -0.171579  -0.085531   \n",
       "2012-09-28     0.258408    1.429542   0.325591  -0.171579  -0.085531   \n",
       "\n",
       "            MarkDown4  MarkDown5       CPI  Weekly_sales_lag  IsHoliday_False  \\\n",
       "Date                                                                            \n",
       "2010-02-05  -0.274567  -0.380216  1.023768          0.906984              1.0   \n",
       "2010-02-05  -0.274567  -0.380216  1.023768          0.066282              1.0   \n",
       "2010-02-05  -0.274567  -0.380216  1.023768          0.700028              1.0   \n",
       "2010-02-05  -0.274567  -0.380216  1.023768          1.013896              1.0   \n",
       "2010-02-05  -0.274567  -0.380216  1.023768          0.593042              1.0   \n",
       "...               ...        ...       ...               ...              ...   \n",
       "2012-09-28   0.131404   0.398139  0.535703          0.273228              1.0   \n",
       "2012-09-28   0.131404   0.398139  0.535703          0.733156              1.0   \n",
       "2012-09-28   0.131404   0.398139  0.535703          0.534664              1.0   \n",
       "2012-09-28   0.131404   0.398139  0.535703          1.094820              1.0   \n",
       "2012-09-28   0.131404   0.398139  0.535703         -0.291051              1.0   \n",
       "\n",
       "            ...  week_44  week_45  week_46  week_47  week_48  week_49  \\\n",
       "Date        ...                                                         \n",
       "2010-02-05  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2010-02-05  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2010-02-05  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2010-02-05  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2010-02-05  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "...         ...      ...      ...      ...      ...      ...      ...   \n",
       "2012-09-28  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2012-09-28  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2012-09-28  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2012-09-28  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2012-09-28  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "            week_50  week_51  week_52  Weekly_Sales  \n",
       "Date                                                 \n",
       "2010-02-05      0.0      0.0      0.0     10.380634  \n",
       "2010-02-05      0.0      0.0      0.0      8.656786  \n",
       "2010-02-05      0.0      0.0      0.0      9.956274  \n",
       "2010-02-05      0.0      0.0      0.0     10.599855  \n",
       "2010-02-05      0.0      0.0      0.0      9.736901  \n",
       "...             ...      ...      ...           ...  \n",
       "2012-09-28      0.0      0.0      0.0      9.081125  \n",
       "2012-09-28      0.0      0.0      0.0     10.024203  \n",
       "2012-09-28      0.0      0.0      0.0      9.617197  \n",
       "2012-09-28      0.0      0.0      0.0     10.765788  \n",
       "2012-09-28      0.0      0.0      0.0      7.924080  \n",
       "\n",
       "[408361 rows x 118 columns]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = WindowGenerator(lookback=6, lookahead=1, batch_size=100, train_df=train_1, test_df=test_1, label_column=['Weekly_Sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-15 16:33:09.632787: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-12-15 16:33:09.931868: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-12-15 16:33:10.339000: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12762/12762 [==============================] - 254s 20ms/step - loss: 2.2298 - mean_squared_error: 2.2298 - mean_absolute_error: 1.0102\n",
      "Epoch 2/10\n",
      "12762/12762 [==============================] - 249s 20ms/step - loss: 1.4121 - mean_squared_error: 1.4121 - mean_absolute_error: 0.7335\n",
      "Epoch 3/10\n",
      "12762/12762 [==============================] - 252s 20ms/step - loss: 1.2308 - mean_squared_error: 1.2308 - mean_absolute_error: 0.6596\n",
      "Epoch 4/10\n",
      "12762/12762 [==============================] - 252s 20ms/step - loss: 1.1401 - mean_squared_error: 1.1401 - mean_absolute_error: 0.6209\n",
      "Epoch 5/10\n",
      "12762/12762 [==============================] - 252s 20ms/step - loss: 1.0779 - mean_squared_error: 1.0779 - mean_absolute_error: 0.5957\n",
      "Epoch 6/10\n",
      "12762/12762 [==============================] - 282s 22ms/step - loss: 1.0319 - mean_squared_error: 1.0319 - mean_absolute_error: 0.5771\n",
      "Epoch 7/10\n",
      "12762/12762 [==============================] - 255s 20ms/step - loss: 0.9983 - mean_squared_error: 0.9983 - mean_absolute_error: 0.5647\n",
      "Epoch 8/10\n",
      "12762/12762 [==============================] - 256s 20ms/step - loss: 0.9710 - mean_squared_error: 0.9710 - mean_absolute_error: 0.5536\n",
      "Epoch 9/10\n",
      "12762/12762 [==============================] - 250s 20ms/step - loss: 0.9476 - mean_squared_error: 0.9476 - mean_absolute_error: 0.5461\n",
      "Epoch 10/10\n",
      "12762/12762 [==============================] - 251s 20ms/step - loss: 0.9283 - mean_squared_error: 0.9283 - mean_absolute_error: 0.5399\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(w1.train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1/12762 [..............................] - ETA: 1:41:54"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-15 17:16:31.169802: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-12-15 17:16:31.270068: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12762/12762 [==============================] - 75s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(w1.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.765172022365282"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(train_1['Weekly_Sales'][6:], pred.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7353736499240329"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(model.evaluate(w1.train)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7669559121447977"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(model.evaluate(w1.test)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 3s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(w1.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0154105598483505"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(test_1['Weekly_Sales'][6:], pred.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Train RMSE | Test RMSE |\n",
    "|------|-------------|-----------|\n",
    "| Logistic Regression | 1.90 | 1.86 | \n",
    "| RandomForest Regressor | 0.76 | 1.76 |\n",
    "| Neural Network | 0.73 | 0.76 |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('assignment-5-tensor')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f7b906d99b2ec91f843337fb9b0616c07f4c02a7a501f2516fb446e3b496cbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
